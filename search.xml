<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Kolmogorov-Arnold Network (KAN)</title>
      <link href="/2024/09/25/machine-learn-kan/"/>
      <url>/2024/09/25/machine-learn-kan/</url>
      
        <content type="html"><![CDATA[<h3 id="Kolmogorov-Arnold-Network-KAN-详细解释"><a href="#Kolmogorov-Arnold-Network-KAN-详细解释" class="headerlink" title="Kolmogorov-Arnold Network (KAN) 详细解释"></a>Kolmogorov-Arnold Network (KAN) 详细解释</h3><h4 id="1-背景与理论基础"><a href="#1-背景与理论基础" class="headerlink" title="1. 背景与理论基础"></a>1. <strong>背景与理论基础</strong></h4><p>Kolmogorov-Arnold Network (KAN) 是基于<strong>Kolmogorov-Arnold 表示定理</strong>构建的神经网络架构，用于解决复杂多维函数的逼近问题。</p><ul><li><p><strong>Kolmogorov 表示定理</strong>指出：任何连续的多维函数 (f(x_1, x_2, \dots, x_n)) 都可以表示为一系列一维函数的叠加形式，即：</p><p>[<br>f(x_1, x_2, \dots, x_n) &#x3D; \sum_{i&#x3D;1}^{N} \varphi_i\left( \sum_{j&#x3D;1}^{n} \psi_j(x_j) \right)<br>]</p><ul><li>其中，(\varphi_i) 和 (\psi_j) 是一维连续函数。</li><li>这为高维输入通过低维非线性函数的组合提供了理论基础，能够逼近任意复杂的多维函数。</li></ul></li></ul><h4 id="2-KAN-网络的主要结构"><a href="#2-KAN-网络的主要结构" class="headerlink" title="2. KAN 网络的主要结构"></a>2. <strong>KAN 网络的主要结构</strong></h4><p>KAN 网络通过分解多维函数，将其映射为多个一维函数的组合，类似于神经网络层之间的非线性变换。</p><p><strong>一般的 KAN 网络结构可以表示为：</strong></p><p>[<br>f(x_1, x_2, \dots, x_n) \approx \sum_{i&#x3D;1}^{N} g_i\left( \sum_{j&#x3D;1}^{n} h_j(x_1, x_2, \dots, x_n) \right)<br>]</p><ul><li><strong>(g_i)</strong>：非线性激活函数，例如 ReLU、Tanh 等，用于引入非线性。</li><li><strong>(h_j)</strong>：线性或非线性映射函数，它对输入 (x_1, x_2, \dots, x_n) 进行加权组合。</li><li>这种结构通过多个激活函数叠加，能够逼近任意复杂的多维连续函数。</li></ul><h4 id="3-KAN-网络的层次化设计"><a href="#3-KAN-网络的层次化设计" class="headerlink" title="3. KAN 网络的层次化设计"></a>3. <strong>KAN 网络的层次化设计</strong></h4><p>KAN 网络通常设计为多层网络，每层都包含多个非线性映射。它通过不同的激活函数和变换，使得模型能够捕获输入数据的复杂模式。</p><ul><li><strong>输入层</strong>：接受多维输入 (x_1, x_2, \dots, x_n)。</li><li><strong>隐层</strong>：通过多个一维激活函数对输入进行非线性映射。</li><li><strong>输出层</strong>：多个非线性激活后的结果组合，输出最终预测值。</li></ul><p><strong>网络的每一层</strong>都可以表示为：</p><p>[<br>h^{(l)}(x) &#x3D; g^{(l)}\left( W^{(l)} h^{(l-1)}(x) + b^{(l)} \right)<br>]</p><ul><li>其中 (h^{(l)}(x)) 是第 (l) 层的输出，(W^{(l)}) 是权重矩阵，(b^{(l)}) 是偏置向量，(g^{(l)}) 是第 (l) 层的激活函数。</li></ul><h4 id="4-KAN-的关键特点"><a href="#4-KAN-的关键特点" class="headerlink" title="4. KAN 的关键特点"></a>4. <strong>KAN 的关键特点</strong></h4><ul><li><strong>多维数据处理能力强</strong>：通过将多维函数分解为一维函数组合，KAN 能够有效处理高维输入。</li><li><strong>非线性表示能力</strong>：通过非线性激活函数的使用，KAN 网络能够逼近复杂的函数关系，适合处理非线性问题。</li><li><strong>可解释性</strong>：Kolmogorov 表示定理为 KAN 的构建提供了理论支持，使得该模型具有一定的可解释性。</li></ul><h4 id="5-KAN-网络的训练"><a href="#5-KAN-网络的训练" class="headerlink" title="5. KAN 网络的训练"></a>5. <strong>KAN 网络的训练</strong></h4><p>KAN 网络的训练与一般的神经网络类似，通常采用反向传播算法（Backpropagation）来最小化损失函数：</p><p>[<br>\text{Loss} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} \left( f(x_i) - \hat{y_i} \right)^2<br>]</p><ul><li>其中 (f(x_i)) 是网络的预测值，(\hat{y_i}) 是真实标签，(m) 是样本数。</li></ul><p>通过梯度下降优化算法，调整网络的权重 (W) 和偏置 (b)，逐步减小损失函数，提升模型的预测精度。</p><h4 id="6-KAN-网络的应用"><a href="#6-KAN-网络的应用" class="headerlink" title="6. KAN 网络的应用"></a>6. <strong>KAN 网络的应用</strong></h4><p>由于 KAN 网络可以很好地逼近高维非线性函数，它在以下应用中表现优异：</p><ul><li><strong>时间序列预测</strong>：KAN 通过捕获复杂的时间依赖性，能处理长期序列的非线性趋势。</li><li><strong>金融建模</strong>：复杂的金融数据中存在大量非线性关系，KAN 可以用来逼近这些复杂关系。</li><li><strong>物理建模</strong>：很多物理过程中的高维数据存在复杂的非线性关系，KAN 通过一维函数的叠加能够很好地模拟这些过程。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习中的常见的激活函数</title>
      <link href="/2024/09/03/machine-learn-Activation-Function/"/>
      <url>/2024/09/03/machine-learn-Activation-Function/</url>
      
        <content type="html"><![CDATA[<h3 id="1-Sigmoid-激活函数"><a href="#1-Sigmoid-激活函数" class="headerlink" title="1. Sigmoid 激活函数"></a>1. Sigmoid 激活函数</h3><p><strong>公式</strong>:<br>$$<br>\sigma(x) &#x3D; \frac{1}{1 + e^{-x}}<br>$$</p><p><strong>特点</strong>:</p><ul><li>输出范围在 (0, 1) 之间。</li><li>非线性函数，允许模型捕捉复杂关系。</li><li>存在“梯度消失”问题，即在输入值很大或很小的时候，梯度接近于0。</li></ul><p><strong>用途</strong>:</p><ul><li>用于二分类问题。</li><li>作为输出层激活函数。</li></ul><h3 id="2-Tanh（双曲正切）激活函数"><a href="#2-Tanh（双曲正切）激活函数" class="headerlink" title="2. Tanh（双曲正切）激活函数"></a>2. Tanh（双曲正切）激活函数</h3><p><strong>公式</strong>:<br>$$ \tanh(x) &#x3D; \frac{e^x - e^{-x}}{e^x + e^{-x}} $$</p><p><strong>特点</strong>:</p><ul><li>输出范围在 (-1, 1) 之间。</li><li>与 Sigmoid 类似，但输出值中心化，以0为中心。</li><li>同样存在梯度消失问题。</li></ul><p><strong>用途</strong>:</p><ul><li>作为隐藏层的激活函数。</li><li>用于输出值需要中心化的情况。</li></ul><h3 id="3-ReLU（线性整流单元）激活函数"><a href="#3-ReLU（线性整流单元）激活函数" class="headerlink" title="3. ReLU（线性整流单元）激活函数"></a>3. ReLU（线性整流单元）激活函数</h3><p><strong>公式</strong>:<br>$$ \text{ReLU}(x) &#x3D; \max(0, x) $$ </p><p><strong>特点</strong>:</p><ul><li>计算效率高。</li><li>缓解了梯度消失问题。</li><li>存在“死亡ReLU”问题，即部分神经元可能永远不激活。</li></ul><p><strong>用途</strong>:</p><ul><li>现代深度学习网络中常用的激活函数。</li><li>特别适合用于隐藏层。</li></ul><h3 id="4-Leaky-ReLU-激活函数"><a href="#4-Leaky-ReLU-激活函数" class="headerlink" title="4. Leaky ReLU 激活函数"></a>4. Leaky ReLU 激活函数</h3><p><strong>公式</strong>:<br>$$ \text{LeakyReLU}(x) &#x3D; \max(0.01x, x) $$ </p><p><strong>特点</strong>:</p><ul><li>解决了 ReLU 的“死亡神经元”问题。</li><li>允许负输入有一个小的非零输出。</li></ul><p><strong>用途</strong>:</p><ul><li>用于隐藏层，特别是在需要解决 ReLU 死亡问题时。</li></ul><h3 id="5-Swish-激活函数"><a href="#5-Swish-激活函数" class="headerlink" title="5. Swish 激活函数"></a>5. Swish 激活函数</h3><p><strong>公式</strong>:<br>$$ \text{Swish}(x) &#x3D; x \cdot \sigma(x) $$ </p><p><strong>特点</strong>:</p><ul><li>连续可微，非单调。</li><li>实验表明在某些任务上比 ReLU 表现更好。</li></ul><p><strong>用途</strong>:</p><ul><li>作为隐藏层的激活函数。</li><li>适用于需要非线性变换的复杂模型。</li></ul><h3 id="6-Softmax-激活函数"><a href="#6-Softmax-激活函数" class="headerlink" title="6. Softmax 激活函数"></a>6. Softmax 激活函数</h3><p><strong>公式</strong>:<br>$$  \text{Softmax}(x_i) &#x3D; \frac{e^{x_i}}{\sum_{j} e^{x_j}} $$ </p><p><strong>特点</strong>:</p><ul><li>将输入转换为概率分布。</li><li>输出值非负，且所有输出值之和为1。</li></ul><p><strong>用途</strong>:</p><ul><li>多分类问题的输出层。</li></ul><p>这些激活函数各有优缺点，选择哪种激活函数通常取决于具体任务和网络结构。在实践中，可能需要尝试不同的激活函数来找到最适合特定问题的那个。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/08/03/hello-world/"/>
      <url>/2024/08/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>友链</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>关于</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>音乐</title>
      <link href="/music/index.html"/>
      <url>/music/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>电影</title>
      <link href="/movie/index.html"/>
      <url>/movie/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
